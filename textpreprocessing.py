# -*- coding: utf-8 -*-
"""TextPreprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hfwRaLBwIUNZYlyEg0TGjiJGEA90EUEF
"""

import pandas as pd
import numpy as np
import re
import string,time
from textblob import TextBlob
import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt')

dataset = pd.read_csv('/content/drive/MyDrive/CMU MOSEI/Audio/Raw 3/Raw3-2/train.csv', encoding = 'ISO-8859-1')
dataset.head()

unique_values_counts = dataset['annotation'].value_counts()
print("Unique values and their counts:")
print(unique_values_counts)

dataset['text'].str.lower()

def remove_html(text):       #removing html
    html_pattern = re.compile('<.*?>')
    return html_pattern.sub(r'', text)

dataset['text'] = dataset['text'].apply(remove_html)

def remove_url(text):       #removing url
    url_pattern = re.compile(r'https?://\S+|www\.\S+')
    return url_pattern.sub(r'', text)

dataset['text'] = dataset['text'].apply(remove_url)

exclude = string.punctuation       #removing punctation
def remove_punc(text):
  return text.translate(str.maketrans('','',exclude))

dataset['text'] = dataset['text'].apply(remove_punc)


#def correct_spelling(text):        #spelling correction
  #return str(TextBlob(text).correct())

#dataset['text'] = dataset['text'].apply(correct_spelling)


def remove_emoji(text):  # removing emoji
    emoji_pattern = re.compile(
        u"[\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002702-\U000027B0"  # other symbols
        u"\U000024C2-\U0001F251"  # enclosed characters
        "]+", flags=re.UNICODE
    )
    return emoji_pattern.sub(r'', text)

dataset['text'] = dataset['text'].apply(remove_emoji)

dataset['text'] = dataset['text'].apply(word_tokenize)

dataset.to_csv('/content/drive/MyDrive/CMU MOSEI/Label1_preprocessed.csv', index=False)